# Smart E-Commerce Orders Data Engineering Pipeline (PySpark)

A full end-to-end **Data Engineering Pipeline project** built using **PySpark** and a modern **Bronze â†’ Silver â†’ Gold** layered architecture.

This project simulates how real-world companies process raw e-commerce transaction data into clean analytics-ready datasets, build Star Schema models, generate KPI reports, and detect fraud patterns.

It is designed as a strong portfolio project for Data Engineering roles.

---

## ðŸš€ Project Overview

This pipeline processes raw online order data and performs:

- Data ingestion from CSV (Bronze Layer)
- Cleaning and transformation (Silver Layer)
- Fraud detection logic
- Star Schema modeling (Gold Layer)
- Business KPI reporting for analytics

The output datasets are stored in **Parquet format**, which is widely used in production data lakes.

---

## âœ… Key Features

- Ingest raw e-commerce transaction data from CSV
- Store raw data into **Bronze Parquet layer**
- Clean, standardize, and enrich data into **Silver layer**
- Add calculated fields such as `total_amount`
- Detect high-value orders with fraud flagging
- Build a complete **Star Schema** (dim + fact tables)
- Generate revenue KPI reports
- Modular job-based PySpark architecture
- Professional GitHub commit workflow (50 commits)

---
